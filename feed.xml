<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://www.ksidorov.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://www.ksidorov.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-08T20:31:40+00:00</updated><id>https://www.ksidorov.com/feed.xml</id><title type="html">Konstantin Sidorov</title><subtitle>A website where I share my research and sometimes produce hot takes on the optimization field. </subtitle><entry><title type="html">How to implicit hitting set</title><link href="https://www.ksidorov.com/blog/2025/ihs/" rel="alternate" type="text/html" title="How to implicit hitting set"/><published>2025-08-08T00:00:00+00:00</published><updated>2025-08-08T00:00:00+00:00</updated><id>https://www.ksidorov.com/blog/2025/ihs</id><content type="html" xml:base="https://www.ksidorov.com/blog/2025/ihs/"><![CDATA[<p>A while ago, a colleague of mine presented a paper on <a href="https://arxiv.org/abs/2412.11954">minimum-size decision trees</a>, and we started discussing their lower bounding strategies. At a certain point, we had the conversation that went approximately like this:<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">1</a></sup></p> <blockquote> <p>— So, they [authors of the paper] employ a few pruning rules, all of them corresponding to some set cover problem.<br/> — Wait, we already played these games:) I am pretty sure we have seen <strong>somewhere</strong> a strategy for solving with set covering.<br/> — Of course we did, it is a common approach to solving MaxSAT problems.</p> </blockquote> <p>After we worked through the paper, we recollected a few more applications of this idea from previous seminars—which is a broad strategy of using <em>implicit hitting sets</em>. While that specific conversation eventually petered out, it got me thinking: for such a conceptually clear idea with so many ways to <em>apply</em> it, there are precious few resources to <em>learn</em> it! So, today, I would like to materialize the conversations I had into what I hope will be a clear explanation of how to implicit hitting set.</p> <h2 id="a-motivating-example-solving-the-knapsack-with-ihs">A motivating example: solving the knapsack with IHS</h2> <p>Implicit hitting set is a rich idea that generalizes to various NP (and even to some beyond-NP) problems. But first, let’s start with something much simpler than decision trees: <em>the 0—1 knapsack problem</em>. As a refresher, in this problem, given a set of items with weights and values, you have to select a subset of items such that:</p> <ul> <li>the total weight does not exceed the knapsack’s capacity,</li> <li>and the total value is maximized.</li> </ul> <p>There are many ways to solve this problem, but for now, we will try doing it by <em>trial and error</em>. For example, let’s try solving the following problem (capacity is 6 units of weight):</p> <table> <thead> <tr> <th style="text-align: left"><strong>Item</strong></th> <th style="text-align: left"><strong>Weight</strong></th> <th style="text-align: left"><strong>Value</strong></th> </tr> </thead> <tbody> <tr> <td style="text-align: left">A</td> <td style="text-align: left">4</td> <td style="text-align: left">5</td> </tr> <tr> <td style="text-align: left">B</td> <td style="text-align: left">2</td> <td style="text-align: left">4</td> </tr> <tr> <td style="text-align: left">C</td> <td style="text-align: left">5</td> <td style="text-align: left">8</td> </tr> </tbody> </table> <p>We want to get as much value as possible out of this. In this problem, you would be justified to explore valid solutions in some manner that goes from one solution to another, a better one. What if we won’t try to build a solution from scratch, but instead ask: “<em>What went wrong last time?</em>” That’s the idea behind implicit hitting sets: it is a dual search approach that solves problems by repeatedly refining its guesses based on counterexamples.</p> <p>Back to our example; without any extra information, we can try being greedy:</p> <blockquote> <p>Would not it be great to take all three items? We can get 17 units of value.</p> </blockquote> <p>Unfortunately, no.</p> <blockquote> <p>…but why?</p> </blockquote> <p>Well, because you cannot take eleven units of weight, you only have six! In fact, <strong>you cannot even take B and C</strong> together.</p> <blockquote> <p>Too bad, but good to know that B and C are incompatible. Can I at least take A and C then? 13 units of value are also good.</p> </blockquote> <p>Still no, but I know what you will ask me; <strong>please don’t take A and C again.</strong></p> <blockquote> <p>Hm, so I have two options now. I can keep C, but now I cannot take anything else. I can drop C; would it be good now to take A and B?</p> </blockquote> <p>Good job. Enough reading, though; try this logic for yourself! The interactive demo below provides you with an implementation for that; you are also welcome to play around with various conflict choices (which are on you to make). What is the smallest collection of conflicts you need to build en route to the optimal solution?</p> <hr/> <style>.bg-danger-mild{background-color:#de474b}.bg-success-mild{background-color:#138a33}</style> <p> <a class="btn btn-primary" data-toggle="collapse" href="#ihsDemo" role="button" aria-expanded="false" aria-controls="ihsDemo" id="toggleIhsBtnTop"> Show the IHS knapsack explorer demo </a> </p> <div class="collapse" id="ihsDemo"> <div class="card card-body"> <h2>Demo: IHS knapsack explorer</h2> <p>Capacity: <strong id="capacity"></strong></p> <div class="row"> <div class="col-md-6 mb-3" id="item-table"></div> <div class="col-md-6 mb-3" id="conflicts"></div> </div> <div class="mb-3"> <button id="reset-button" class="btn btn-secondary">Start over</button> </div> <h3>Item subsets</h3> <div id="conflict-picker"></div> <div id="results"></div> </div> </div> <p> <a class="btn btn-primary" data-toggle="collapse" href="#ihsDemo" role="button" aria-expanded="false" aria-controls="ihsDemo" id="toggleIhsBtnBot" style="display: none"> Show the IHS knapsack explorer demo </a> </p> <script>function powerset(e){return e.reduce((e,t)=>e.concat(e.map(e=>[...e,t])),[[]])}function blocker(e){return conflicts.find(t=>t.every(t=>e.map(e=>e.id).includes(t)))}function evaluate(e){const t=e.reduce((e,t)=>e+t.weight,0);return{weight:t,value:e.reduce((e,t)=>e+t.value,0),feasible:t<=capacity,blockedBy:blocker(e)}}function renderTable(){d3.select("#capacity").text(capacity);const e=d3.select("#item-table").html("").append("table").attr("class","table table-bordered");e.append("thead").append("tr").selectAll("th").data(["Item","Weight","Value"]).enter().append("th").text(e=>e);const t=e.append("tbody").selectAll("tr").data(items).enter().append("tr");t.append("td").text(e=>e.id),t.append("td").text(e=>e.weight),t.append("td").text(e=>e.value)}function renderConflictPicker(e){function t(){const{weight:e}=evaluate(l);e<=capacity?a.text(`Current weight: ${e}; not overweight yet!`):a.text(`Current weight: ${e}`),s.attr("disabled",e<=capacity||null)}const n=d3.select("#conflict-picker").html("").append("div").attr("class","card card-body mt-4");n.append("p").text("\ud83d\udca5 Overweight subset detected. Uncheck items to reduce weight:");let l=[...e];const c=n.append("div").attr("class","form-group form-check form-check-inline").selectAll("label").data(e).enter().append("label").attr("class","form-check-label mr-3");c.append("input").attr("type","checkbox").attr("class","form-check-input").attr("checked",!0).on("change",function(e,n){this.checked?l.push(n):l=l.filter(e=>e!==n),t()}),c.append("span").text(e=>e.id);const a=n.append("p").attr("id","weight-display").attr("class","small mt-2"),s=n.append("button").attr("id","confirm-conflict").attr("class","btn btn-primary btn-sm mt-2").text("Add a conflicting set of items").on("click",function(){evaluate(l).weight>capacity&&(conflicts.push(l.map(e=>e.id)),renderConflicts(),renderResults(),d3.select("#conflict-picker").html(""),autoIterate())});t()}function renderConflicts(){const e=d3.select("#conflicts").html("");if(e.append("h5").text("Conflict sets of items"),0===conflicts.length)return void e.append("p").attr("class","text-muted").text("No conflicts yet.");const t=e.append("ul").attr("class","pl-3");conflicts.forEach(e=>{t.append("li").text(`{${e.join(", ")}}`)})}function renderResults(){const e=powerset(items).map(e=>({subset:e,...evaluate(e)}));e.sort((e,t)=>t.value-e.value);const t=e.filter(e=>e.blockedBy===undefined).reduce((e,t)=>t.value>e.value?t:e,{value:-1}),n=d3.select("#results").html("");t&&t.feasible?n.append("p").attr("class","text-success font-weight-bold mt-2").text(`\ud83c\udf89 Optimal subset: {${t.subset.map(e=>e.id).join(", ")}}`):(n.append("p").attr("class","text-danger font-weight-bold mt-2").text("\u26a0\ufe0f Not a feasible subset yet; please choose a conflicting set of items."),renderConflictPicker(t.subset)),n.selectAll("div.subset").data(e).enter().append("div").attr("class",e=>{let n="p-2 mb-1 rounded border ";return e.blockedBy!==undefined?n+="bg-muted":(n+="text-light ",e.feasible?n+="bg-success-mild ":n+="bg-danger-mild ",e.value===t.value&&(n+=" font-weight-bold"),n)}).attr("style",e=>e.blockedBy===undefined?null:"text-decoration: line-through").text(e=>{return`{${e.subset.map(e=>e.id).join(", ")}} \u2192 weight=${e.weight}, value=${e.value}`})}function autoIterate(){const e=powerset(items).map(e=>({subset:e,...evaluate(e)})).filter(e=>e.blockedBy===undefined).reduce((e,t)=>t.value>e.value?t:e,{value:-1});e.feasible||renderConflictPicker(e.subset)}function resetAll(){conflicts=[],d3.select("#conflict-picker").html(""),renderConflicts(),renderResults()}document.addEventListener("DOMContentLoaded",function(){var e=document.getElementById("toggleIhsBtnTop"),t=document.getElementById("toggleIhsBtnBot");document.getElementById("ihsDemo");$("#ihsDemo").on("shown.bs.collapse",function(){e.textContent="Hide the IHS knapsack explorer demo",t.style.display="",t.textContent="Hide the IHS knapsack explorer demo"}),$("#ihsDemo").on("hidden.bs.collapse",function(){e.textContent="Show the IHS knapsack explorer demo",t.style.display="none"})});const items=[{id:"A",weight:3,value:4},{id:"B",weight:4,value:5},{id:"C",weight:2,value:3},{id:"D",weight:5,value:8}],capacity=6;let conflicts=[];d3.select("#reset-button").on("click",resetAll),renderTable(),renderConflicts(),renderResults();</script> <hr/> <h2 id="the-general-idea">The general idea</h2> <p>First, let’s have a look at what we have just done. In this approach to the knapsack problem, we maintained the <em>conflict sets</em> and repeated the following:</p> <ol> <li>Find the best solution that avoids all known conflicts.</li> <li>Is it feasible? Then stop, because it is also optimal.</li> <li>By this point, our solution is infeasible; inspect the solution and extract a conflict out of it.</li> </ol> <p>And now the best part: <strong>this approach does not rely on anything knapsack-specific</strong>. All it requires is that:</p> <ul> <li>You can state the problem in terms of “valid” versus “invalid” configurations.</li> <li>Given an invalid configuration, you can extract a <em>conflict</em> out of it: a set of elements that cannot be added together.</li> <li>Given a <em>set</em> of invalid configurations, you can find the “largest” that avoids all conflicts.</li> </ul> <p>The “duality” comes from this loop: instead of searching over the space of solutions (primal) until you exhaust all of it, you instead explore the space of explanations (dual) until you know enough of it. This workflow is especially powerful when your problem has no compact formulation, but it can provide you with counterexamples when you ask for it. You don’t need to model the whole thing up front — just keep learning what doesn’t work.</p> <p>Here is a graphical summary of this technique:</p> <p><img src="/assets/img/ihs.svg"/></p> <p>You can also narrate it in the minimization form:</p> <ul> <li>You can state the problem in terms of “valid” versus “invalid” configurations. (same)</li> <li>Given an invalid configuration, you can extract a core out of it: a set of elements that cannot be removed together.</li> <li>Given a <em>set</em> of invalid configurations, you can find the “smallest” that covers all the cores.</li> </ul> <p>Given this workflow, if you can fit your problem in this scheme, you can also solve it: at least, all the ingredients are in place!</p> <blockquote> <p>But <strong>how</strong> can I apply this?</p> </blockquote> <h2 id="where-ihs-shows-up">Where IHS shows up</h2> <p>In more than a few domains, actually! To give a few examples:</p> <h3 id="optimization">Optimization</h3> <p>First, let’s consider one of the most cited success stories of the implicit hitting set: the MaxSAT problem <a class="citation" href="#10.1007/978-3-642-23786-7_19">(Davies and Bacchus 2011)</a>. The problem has the following structure: given \(m\) <em>clauses</em> with <em>weights</em> \(w_1, \dotsc, w_n &gt; 0\) over Boolean variables, find an assignment that <em>minimizes the weight of violated clauses</em>.<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">2</a></sup></p> <p>The problem structure suggests a natural conflict description: an unsatisfiable subset of the input clauses. (In SAT literature, this set is referred to as <em>core</em>.) That, in turn, suggests a way to extract conflicts: given a set of clauses that are supposed to be satisfied, feed it into a SAT solver; here is what can happen:</p> <ul> <li>The SAT solver returns a <em>satisfying</em> assignment: great, this is the optimal solution.</li> <li>The SAT solver returns an <em>UNSAT</em> verdict: then we request an UNSAT core of the formula and add it to the core set.</li> </ul> <p>Once we set up the same conflict-avoidant logic as in our knapsack example, we get the following IHS loop:</p> <ol> <li>Find the minimum-weight hitting set of all known cores.</li> <li>Construct a SAT formula from this hitting set and halt if the assignment is found.</li> <li>Recover an UNSAT core and add it to the core set; repeat.</li> </ol> <h3 id="model-debugging">Model debugging</h3> <p>Just like you can find the <em>largest satisfiable</em> set, you can also find the <em>smallest unsatisfiable</em> one. This is an important problem when you, for example, are debugging a constraint model that is unsatisfiable but should not be for some extra-modeling reasons (e.g., domain knowledge). More precisely, the problem, known as the <em>smallest minimal unsatisfiable set (MUS) problem</em>, is as follows: given \(m\) clauses<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> \(\Omega = \{ \omega_1, \dotsc, \omega_m \}\) over Boolean variables, find its smallest unsatisfiable subset \(\Omega^* \subseteq \Omega\) <a class="citation" href="#10.1007/978-3-319-23219-5_13">(Ignatiev et al. 2015)</a> .</p> <p>With a few examples under the belt, the dual of this problem is clear:</p> <ul> <li>we need to avoid all <em>not</em> unsatisfiable subsets \(\Omega' \subset \Omega\),</li> <li>so any unsatisfiable set has to contain one of the clauses in a set \(C := \Omega \setminus \Omega'\) of <em>omitted</em> clauses. Any subset of clauses \(C\) with this property—discarding it leaves a satisfiable formula—is called a <em>correction</em> subset. If adding any further clause to \(C\) breaks this, like a reverse Jenga puzzle, then it is a <em>maximal correction set</em> (MCS).</li> </ul> <p>With that said, here is the IHS approach we get:</p> <ol> <li>Find the minimum-weight hitting set of all known MCSes.</li> <li>Construct a SAT formula from this hitting set and halt if a solver declares it UNSAT.<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">4</a></sup></li> <li>Recover an MCS and add it to the set of known MCSes; repeat.</li> </ol> <h3 id="inferring-functional-dependencies">Inferring functional dependencies</h3> <p>You can also discover the IHS formulation for enumeration problems, rather than the ones of optimization. For a widely known example of such a problem, consider the situation described in <a class="citation" href="#MANNILA199483">(Mannila and Räihä 1994)</a>: You have a relational table, for example, like <a href="https://commons.wikimedia.org/wiki/File:DVD_Rental_Query.png">this</a> one:</p> <table> <thead> <tr> <th style="text-align: left">Title</th> <th style="text-align: left">Release year</th> <th style="text-align: center">Length</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">West Lion</td> <td style="text-align: left">2006</td> <td style="text-align: center">159</td> </tr> <tr> <td style="text-align: left">Sassy Packer</td> <td style="text-align: left">2005</td> <td style="text-align: center">154</td> </tr> <tr> <td style="text-align: left">Jingle Sagebrush</td> <td style="text-align: left">2005</td> <td style="text-align: center">159</td> </tr> </tbody> </table> <p>Clearly, some of the columns are going to <em>functionally determine</em> the others; for example, if you know Title and Release year, you should know Length. However, not all of the functional dependencies are going to be “natural,” such as the relation (Length, Release year) → Title. Knowing the relations that hold in this table—even if not marked explicitly—can be helpful for all sorts of reasons:</p> <ul> <li><em>Pattern mining</em>: knowing that some if-else pattern holds unconditionally on your dataset is as good as it gets, if you are looking for dependencies.</li> <li><em>Database design</em>: if a relation has a valid functional dependency that does not correspond to some table key, making that dependency explicit is helpful for data integrity.</li> <li><em>Query optimization</em>: similarly, if a query optimizer knows that some column is defined by another, it can leverage such information to short-circuit some table joins or even avoid table lookups altogether <a class="citation" href="#10.1145/146931.146932">(Siegel, Sciore, and Salveter 1992)</a>.</li> </ul> <p>A good start would be to enumerate <em>all</em> such dependencies. Again, by the IHS playbook, we need to determine the following:</p> <ol> <li>When \((a_1, \dotsc, a_n) \to b\) is <em>not</em> a functional relation? That would mean that the column \(b\) in some two rows \(p, q\) is indistinguishable from columns in \(a\), in other words, when \(p(a_1, \dotsc, a_n) = q(a_1, \dotsc, a_n)\) but \(p(b) \neq q(b)\) for some rows \(p, q\).</li> <li>How to define a conflict? Given the “witness” rows \(p\) and \(q\) and the dependent column \(b\), we cannot discard \((a_1, \dotsc, a_n)\) from the set \(\Omega\) of all columns (similarly to the MUS example above).</li> <li>How to trim a conflict? Similarly to before, try adding more columns to the left-hand side \((a_1, \dotsc, a_n)\) without ending up discriminating the rows \(p\) and \(q\); once this is no longer possible, we found the maximal non-functional left-hand side and minimal conflict.</li> <li>How do <em>valid</em> solutions look like? They should add one of the conflict columns for all conflicts discovered as described above.</li> </ol> <p>Well, that was a lot; here is a short summary to match problems with their IHS ingredients:</p> <table> <thead> <tr> <th style="text-align: left"><strong>Problem</strong></th> <th style="text-align: left"><strong>Conflict structure</strong></th> <th style="text-align: left"><strong>Conflict extraction</strong></th> <th style="text-align: left"><strong>Hitting set interpretation</strong></th> </tr> </thead> <tbody> <tr> <td style="text-align: left">MaxSAT</td> <td style="text-align: left">UNSAT core</td> <td style="text-align: left">SAT solver run</td> <td style="text-align: left">A subset of clauses avoiding all UNSAT cores</td> </tr> <tr> <td style="text-align: left">Smallest MUS</td> <td style="text-align: left">Minimal correcting subsets</td> <td style="text-align: left">“Grow” procedure (add clauses to MCS and call a SAT solver)</td> <td style="text-align: left">A subset of clauses that does not fully discard any MCS</td> </tr> <tr> <td style="text-align: left">Functional relation inference</td> <td style="text-align: left">Non-discriminating column sets</td> <td style="text-align: left">Pairwise row testing</td> <td style="text-align: left">A subset of columns that does not collate any pair of rows disagreeing on the right-hand side</td> </tr> </tbody> </table> <h2 id="miscellaneous-tricks">Miscellaneous tricks</h2> <p>Of course, while this scheme is simple to describe, executing it <em>well</em> is not so simple. Effective implementations of the IHS workflow incorporate a variety of extra techniques; for example:</p> <p><strong>Conflict/core extraction heuristics</strong>. Better core extraction = fewer iterations. For example, one way to speed up MUS extraction is to observe that:</p> <ul> <li>MCSes not only state that some subset is invalid, but also <em>give an assignment</em> that has to be falsified by any MUS (which has not happened on the IHS iteration of interest);</li> <li>and similar assignments (e.g., the ones obtained by flipping one bit) could yield <em>different</em> MCSes. This technique is known as <em>model rotation</em> and, while not giving any formal guarantees, it is known to be helpful for MUS extraction <a class="citation" href="#10.1007/978-3-642-21581-0_14">(Marques-Silva and Lynce 2011)</a>.</li> </ul> <p><strong>Smarter hitting set solvers</strong>. Hitting set computation is NP-complete; even if it is easier than handling most of the problems here directly, it is still not trivial. Therefore, hitting set solvers also commonly employ:</p> <ul> <li>integer linear programming solvers to get high-quality relaxations <a class="citation" href="#10.1007/978-3-642-23786-7_19">(Davies and Bacchus 2011)</a>,</li> <li>greedy approximations for fast lower bounds <a class="citation" href="#staus2024wittyefficientsolvercomputing">(Staus et al. 2024)</a>,</li> <li>and adding domain-specific constraints to avoid exploring <em>clearly</em> infeasible hitting sets <a class="citation" href="#10.5555/3032027.3032040">(Saikko, Wallner, and Järvisalo 2016)</a>.</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>IHS dualization elegantly delegates search (candidate generation) to explanation of infeasibility (conflict learning). As any other versatile idea, it has many names in other fields; here are a few:</p> <ul> <li><em>conflict-driven clause learning</em> from SAT solving,</li> <li><em>nogood learning</em> in constraint programming,</li> <li><em>cutting plane</em> approaches in integer programming,</li> <li><em>counterfactual explanations</em> in machine learning,</li> <li><em>counter-example guided abstract refinement</em> in program synthesis.</li> </ul> <p>Implicit Hitting Set dualization is a unifying perspective for tackling hard problems. Whether you’re debugging a program, optimizing a Boolean formula, or solving a puzzle, <strong>if it is easier to diagnose non-solutions than to enumerate valid solutions, IHS is a tool you want to consider.</strong></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:2"> <p>I do not recollect the conversation on a word-by-word level, so the source for the next block is “I made it up.” That said, I recollect that we <em>had</em> a discussion that back-referenced us from this paper to previous IHS applications. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>The more common problem definition also discriminates between <em>hard</em> clauses that have to be satisfied unconditionally, and <em>soft</em> clauses that can be violated for a penalty. However, it is equivalent to the text definition: just set all hard clause weights to a number larger than the sum of soft clause weights, and declare the problem UNSAT if any of the hard clauses is violated in the optimal solution. In the blog text, I stick to the soft-only definition, as it makes the exposition of the approach more accessible. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>But it might as well be an arbitrary constraint, albeit with less space for domain-specific techniques for correcting set extraction. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:5"> <p>Yes, this is the exact opposite of the MaxSAT condition; this only makes sense given the duality between those two problems. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="techniques"/><category term="ihs"/><category term="optimization"/><summary type="html"><![CDATA[A tour of implicit hitting set workflow and applications]]></summary></entry><entry><title type="html">A new approach to solving hard scheduling problems via disjointness</title><link href="https://www.ksidorov.com/blog/2025/unite-and-lead/" rel="alternate" type="text/html" title="A new approach to solving hard scheduling problems via disjointness"/><published>2025-06-15T00:00:00+00:00</published><updated>2025-06-15T00:00:00+00:00</updated><id>https://www.ksidorov.com/blog/2025/unite-and-lead</id><content type="html" xml:base="https://www.ksidorov.com/blog/2025/unite-and-lead/"><![CDATA[<p>I’m excited to share that my latest paper, “Unite and Lead: Finding Disjunctive Cliques for Scheduling Problems,” co-authored with <a href="https://imkomarijnissen.com">Imko Marijnissen</a> and <a href="https://emirdemirovic.com">Emir Demirović</a>, has been accepted to CP 2025! For those who want all the technical details, you can read the full paper <a href="/assets/pdf/cp2025-unite-and-lead.pdf">here</a>. But for everyone else, I wanted to write this post to explain the core ideas in a more accessible way.</p> <h2 id="the-blind-spots-of-specialization">The blind spots of specialization</h2> <p>Imagine you’re managing a very complex project—like building a factory or designing a CPU. You have hundreds of tasks, and each task requires specific resources: a certain number of workers, a particular machine, a specific tool, and so on. Your goal is to create a schedule that completes the project as quickly as possible without any resource conflicts (like needing 11 workers when you only have 10).</p> <p>This is a classic <strong>scheduling problem</strong>. In the world of computer science, we frequently use general-purpose software tools called “solvers” to tackle them. These solvers are smart, but the constraint programming solvers—the ones commonly used in scheduling—have a particular way of looking at the problem: they focus on one constraint at a time.</p> <p>A solver might look at the “workers” constraint and ensure you never schedule too many tasks at once for your team. Then, it will separately look at the “machine” constraint to make sure the machine isn’t double-booked. This is a very effective strategy, but it can create blind spots. By looking at each resource in isolation, the solver can miss the bigger picture—the <em>global structure</em> of the problem that arises from how different constraints interact.</p> <p>In a way, it’s like trying to solve a Sudoku puzzle by only ever looking at one row at a time, then one column at a time, and then one 3x3 box at a time. Sure, this is a plausible strategy, and with proper accounting, it eventually succeeds; however, this way you will miss crucial insights!</p> <h2 id="a-puzzle-that-fools-modern-solvers">A puzzle that fools modern solvers</h2> <p>To see how the local view can fail, consider a small puzzle; in our work, we call it the <em>3n problem</em>. Let’s say you have six tasks. Each requires a different mix of three resources. Your job is to schedule them. Try it for yourself below! You can drag the tasks onto the timeline. <strong>Can you schedule any two tasks at the same time?</strong></p> <iframe class="iframe-resize" src="/assets/html/cp2025-3n.html" frameborder="0" scrolling="no"></iframe> <p>As you surely discovered by this point, you can’t. Any pair of tasks you choose will overload one of the resources. For example:</p> <ul> <li>Two yellow tasks conflict on Resource 1.</li> <li>A yellow and a green task conflict on Resource 1.</li> <li>A yellow and a blue task conflict on Resource 2.</li> </ul> <p>…and so on.</p> <p>Every single pair of tasks is <strong>disjoint</strong>—they cannot overlap in time. The only solution is to schedule all six tasks sequentially, one after the other. This seems obvious when you look at the whole picture. But for a standard constraint solver, it’s surprisingly tricky:</p> <ul> <li>The solver checks the “Resource 1” constraint and sees <em>some</em> pairs of tasks in conflict.</li> <li>Then it checks the “Resource 2” and finds <em>some other</em> conflicting pairs.</li> </ul> <p>But no single resource constraint tells the solver that <em>all</em> tasks are pairwise disjoint. To figure that out, it needs to combine the information from all three resource constraints. Without a mechanism to do this, the solver resorts to brute-force trial and error, which takes exorbitant amounts of time for larger versions of this puzzle.</p> <h2 id="our-solution-the-disjointness-detective">Our solution: the disjointness detective</h2> <p>This is where our work comes in. We give the solver a new set of tools to reason about the global structure of the problem by focusing on this idea of disjointness. Our approach has two main parts.</p> <p><strong>Mining for disjointness</strong>. First, we upgrade the existing parts of the solver to become “disjointness miners.” Their job is to report back whenever they can prove that two tasks cannot overlap. This can be for various reasons:</p> <ul> <li>Resource clash: like in the puzzle above, two tasks need more of a resource than is available.</li> <li>Precedence: task A must finish before task B can start.</li> <li>No-good learning: a solver has learned from a previous search round that scheduling tasks C and D together leads to a dead end.</li> </ul> <p><strong>A <code class="language-plaintext highlighter-rouge">SelectiveDisjunctive</code> propagator</strong>. Next, we introduce a new <code class="language-plaintext highlighter-rouge">SelectiveDisjunctive</code> constraint and a propagator for it. While this does not change the set of feasible schedules, you can think of it as a master detective. It takes all the disjointness clues found by the miners and puts them together on a big <em>conflict graph</em>. Each task is a node on the graph, and an edge is drawn between any two tasks that are marked as disjoint by miners.</p> <p>The detective’s job is to look for cliques in this graph: groups of tasks where every task is connected to every other task in the group. In our context, any clique is a set of tasks that must all be scheduled sequentially. Once a clique is found, the detective does a quick calculation: it sums up the durations of all tasks in the clique. If that total duration is longer than the available time window for those tasks, it’s an “Aha!” moment. The detective has found a conflict, and it tells the solver, “This branch of the search is impossible. Backtrack now!”</p> <p>Here’s an interactive visualization of that process. Each node corresponds to a task that takes a single time unit; the numbers in the node give a time interval available for a task: 1..6 means that a task starts at time 1 or later and finishes at time 6 or earlier. Click the toggles to apply different resource constraints. As you do, you’ll see the “disjointness” edges appear. Watch what happens when a clique forms!</p> <iframe class="iframe-resize" src="/assets/html/cp2025-clique.html" frameborder="0" scrolling="no"></iframe> <p>This ability to find conflicting cliques by combining information from many different constraints is the superpower of our new approach. It gives the solver a global perspective that it was previously lacking.</p> <h2 id="and-does-it-work">And does it work?</h2> <p>In a word: <strong>yes</strong>!</p> <p>When we tested our approach on the 3n puzzle that stumped other solvers, ours solved it instantly, and for much larger versions at that. More importantly, when we applied it to well-known, difficult scheduling benchmarks from the research community, we saw some major improvements. On problems with high <em>resource contention</em>—meaning resources are scarce and tasks are constantly competing—our approach sometimes improved the solver’s speed by <strong>orders of magnitude</strong>. (That means instead of taking hours, it took minutes or even seconds!)</p> <p>We were also thrilled to discover <strong>new state-of-the-art bounds</strong> for a handful of problems that have been studied by researchers for years. We managed to:</p> <ul> <li>discover the best-known solutions for two RCPSP/max and four RCPSP instances,</li> <li>improve the lower bounds on the achievable objective value for sixteen RCPSP/max and four RCPSP instances,</li> <li>and completely solve seven instances that were previously open along the way.</li> </ul> <p>For us, it’s like finding a new, faster route through a well-trodden maze.</p> <h2 id="the-takeaways">The takeaways</h2> <p>The big lesson from our work is that for complex problems, looking at the pieces in isolation isn’t enough. By developing ways for the solver to unite information from many sources and reason about the global structure of the problem, we can achieve breakthroughs that were previously out of reach.</p> <p>There’s still a lot more to explore, but we’re excited about this new direction for building smarter and more powerful constraint solvers. Thanks for reading!</p>]]></content><author><name></name></author><category term="paper-announcement"/><category term="cp"/><category term="scheduling"/><summary type="html"><![CDATA[An overview of the scheduling technique explored by us in our CP 2025 conference submission.]]></summary></entry><entry><title type="html">CP 2024 impressions</title><link href="https://www.ksidorov.com/blog/2024/cp2024/" rel="alternate" type="text/html" title="CP 2024 impressions"/><published>2024-09-06T00:00:00+00:00</published><updated>2024-09-06T00:00:00+00:00</updated><id>https://www.ksidorov.com/blog/2024/cp2024</id><content type="html" xml:base="https://www.ksidorov.com/blog/2024/cp2024/"><![CDATA[<p>In this post, I want to share some of my takeaways from the <a href="https://cp2024.a4cp.org/">CP 2024</a> conference this week in Girona. While this event, as usual, was stacked with a variety of high-quality optimization talks, I can see a few overarching themes I think would be worthwhile to share.</p> <p>Of course, condensing a week’s worth of technical content to a single post can never have a hint of completeness in it, therefore, I will do my best to share a general impression of the field as I see it without trying to dive into any specific technical details. If you are in Delft or nearby, however, I would welcome you to <a href="https://m-o-o.org/sessions/2024/09/09/">the MOO session</a> this Monday, September 9, where I will lead a more in-depth discussion over the same narrative points.</p> <p>Now, without further ado, let’s dive into the first point I want to make, which is…</p> <h2 id="good-old-fashioned-ai-is-here-to-stay"><a href="https://en.wikipedia.org/wiki/GOFAI">Good old-fashioned AI</a> is here to stay</h2> <p>One of the major takeaways from this year’s papers is that <strong>some of the less known or recognized ideas from earlier days are worth being re-explored</strong>, at least because the computational resources we have now do not look like anything we have had in the heyday of <a href="#" data-toggle="tooltip" data-original-title="Good old-fashioned AI">GOFAI</a>. As for the specific examples, I cannot avoid mentioning an invited talk by Ian Gent <a class="citation" href="#gent:LIPIcs.CP.2024.1">(Gent 2024)</a> on <em>Solvitaire</em>, software for evaluating the winnability of solitaire games which narrowed the winnability range of Klondike to a fraction of a percentage point <a class="citation" href="#blake2024winnabilityklondikesolitairepatience">(Blake and Gent 2024)</a>. This approach achieves impressive computational results – but it does so without reaching to ideas unrelated to search: a good way to summarize this approach would be “running a depth-first search, maintaining the transposition table, and using the dominance pruning rules.”</p> <p>Another direction worth mentioning here is <a href="https://didp.ai/"><em>domain-independent dynamic programming</em></a>, introduced with a tutorial by Chris Beck. Dynamic programming is one of the foundational CS curriculum topics, yet most of the attention in this context is diverted to ad-hoc implementation of various techniques. An approach that brings it closer to model-and-solve is certainly welcome!</p> <p>For a more modern spin, I would like to mention an approach for improving the bin packing propagation with GPUs <a class="citation" href="#tardivo_et_al:LIPIcs.CP.2024.28">(Tardivo, Michel, and Pontelli 2024)</a>. While the first association with GPU programming is surely the linear algebra computations, it turns out you can also use it to parallelize the calculation of different lower bounds, making it useful for getting many uncorrelated lower bounds for the price of one. I think using GPUs in search is yet another underexplored direction; looking forward to more!</p> <p>A hallmark of GOFAI approaches, however, is that they require substantial effort during the implementation to get it right, ranging from establishing the workflow to correcting the smallest of implementation details, or, as Ian Gent has put it, it takes:</p> <blockquote><p>Punctilious tenacious precision.</p><cite><a class="citation" href="#gent:LIPIcs.CP.2024.1">(Gent 2024)</a></cite></blockquote> <p>Given that, it is hardly surprising that more than a few papers support the next major trend:</p> <h2 id="trust-is-an-appreciating-asset">Trust is an appreciating asset</h2> <p><strong>Disclaimer</strong>: both of the papers I have co-authored for this conference fall into this group, so I have an inherent bias towards this subfield.</p> <p>To counter-balance the previous point, several papers have explored ways to <em>justify</em> various claims made by optimization algorithms. To start, a paper by Berg et al. has introduced an approach for justifying a <em>without loss of generality</em> reasoning in <em>Pacose</em> MaxSAT solver <a class="citation" href="#berg_et_al:LIPIcs.CP.2024.4">(Berg et al. 2024; Paxian, Reimer, and Becker 2018)</a>. The key challenge behind justifying this type of reasoning is that it introduces statements that are not implied but do not <em>really</em> change the problem: think symmetry breaking or pure clause elimination.</p> <p>Justifying a claim by any solver is tricky, but the situation for the <em>constraint</em> solvers is particularly hard because they employ a wide range of reasoning techniques to propagate through different constraints. We addressed this in <a class="citation" href="#flippo_et_al:LIPIcs.CP.2024.11">(Flippo et al. 2024)</a> with an approach that first writes the proof <em>scaffold</em> and expands the propagations necessary to justify the “scaffolded” claims later on.</p> <p>All of this involves justifying different parts of model-and-solve workflows; not every optimization algorithm can be described this way, however, with dynamic programming being a notable exception. We proposed a way to do this in <a class="citation" href="#demirovic_et_al:LIPIcs.CP.2024.9">(Demirović et al. 2024)</a> by encoding the dynamic programming states with new variables and mirroring the individual transitions.</p> <p>All in all, as the search algorithms become more important, the need for justifying their results naturally grows as well. Luckily, this is much less of a problem than in, say, learning-based approaches. If you have an idea of how to justify a decision-making procedure (and what to justify in the first place), there is a good chance it has either not been executed yet or differs in some important context; I think we will see more of this action in the next CP conference!</p> <h2 id="incomplete-search-is-worth-more-than-a-passing-mention">Incomplete search is worth more than a passing mention</h2> <p>In many problems, however, the optimality claim is not an asset; the only thing that matters is finding good solutions. Quite a few papers explored this idea this year; in fact, the best paper award went to the work that proposed new local search operators for MIP solving, showing impressive results on the MIPLIB <a class="citation" href="#lin_et_al:LIPIcs.CP.2024.19">(Lin, Zou, and Cai 2024)</a>. Given that many MIP models stem from practical settings without a meaningful interpretation for a lower bound, this certainly looks like a promising result!</p> <p>Another noteworthy work by Chen et al. introduces an approach for running a local search for pseudo-Boolean optimization problems <em>in parallel</em> <a class="citation" href="#chen_et_al:LIPIcs.CP.2024.5">(Chen et al. 2024)</a>. The parallelism here serves both as a way to run many parallel searches and as a remedy against local optima which shares good solutions to re-fire searches that will stall later.</p> <p>I have to admit I do not have a clear idea of what is missing in this subfield of optimization. On the other hand, the local search seems to be an evergreen idea that is always on the table… and clearly useful to keep in mind.</p> <h2 id="data-generated-by-search-algorithms-is-underexploited">Data generated by search algorithms is underexploited</h2> <p>Most of the talks mentioned above were about various techniques for or around the search algorithms; however, there is undeniably a lot of value in learning from data. On a surface, this area does seem to be fit for learning approaches, as the algorithms have to make a lot of decisions and therefore produce a lot of data. However, my takeaway from this year is that <strong>there are many more patterns to mine</strong> in data produced by optimization algorithms than we do now.</p> <p>That is not to say, of course, that there is no effort; quite the contrary, there have been a few exciting talks showing new ways of working with data “in the loop”. For example, <a class="citation" href="#parjadis_et_al:LIPIcs.CP.2024.22">(Parjadis et al. 2024)</a> suggest training a GNN model to produce good Lagrangean multiplies for the traveling salesperson problem. I think this is a promising approach, not least because it seems to only assume that the problem in hand has a “convenient” Lagrangian relaxation; I wonder if we see this approach used in more problem domains next year.</p> <p>There is also a lot to say about reasoning over the <em>constraints</em> of a problem. <a class="citation" href="#michailidis_et_al:LIPIcs.CP.2024.20">(Michailidis, Tsouros, and Guns 2024)</a> explore this idea with the help of large language models. This seems to be a promising way to address the “open world” problem that appears in applied modeling when the optimization problem typically undergoes many iterations which include both the optimization people and the domain experts. Overall, this seems to be a promising way to make optimization technologies more accessible, hopefully with more applications down the line.  </p> <h2 id="conclusion">Conclusion</h2> <p>Overall, that was an exciting event, and an inspiring one at that; not only there is a lot of action going on, but there are several topics that are clearly in high demand. I expect that over the next year, we will see a lot of new ways of justifying various algorithms—or their parts—as well as novel combinations of search techniques across the field. Of course, the usual suspects of novel local search techniques are new propagators are never off the table:) And that’s it for now; goodbye, Girona, and see you in Glasgow next year!</p> <div class="row mt-3">     <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240906_154721-480.webp 480w,/assets/img/20240906_154721-800.webp 800w,/assets/img/20240906_154721-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/20240906_154721.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>     </div>     <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240902_205957-480.webp 480w,/assets/img/20240902_205957-800.webp 800w,/assets/img/20240902_205957-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/20240902_205957.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>     </div> </div>]]></content><author><name></name></author><category term="conference-review"/><category term="conference"/><category term="cp"/><summary type="html"><![CDATA[My take on the key trends from the CP 2024 conference.]]></summary></entry></feed>